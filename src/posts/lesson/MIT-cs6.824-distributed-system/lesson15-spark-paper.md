---
category: 
  - 分布式系统
tag:
  - 分布式系统
---

- [弹性分布式数据集：内存集群计算的一种容错抽象](#弹性分布式数据集内存集群计算的一种容错抽象)
  - [摘要](#摘要)
  - [引言](#引言)

# 弹性分布式数据集：内存集群计算的一种容错抽象

## 摘要

我们提出了弹性分布式数据集（RDDs），这是一种分布式内存抽象，它允许程序员以容错的方式在大型集群上进行内存中的计算。RDDs 是由当前计算框架处理效率低下的两类应用所推动的：迭代算法和交互式数据挖掘工具。在这两种情况下，将数据保存在内存中可以将性能提高一个数量级。

为了有效地实现容错，RDDs 提供了一种受限形式的共享内存，它基于粗粒度的转换而不是对共享状态的细粒度更新。然而，我们表明 RDDs 具有足够的表现力，可以捕获广泛的计算类型，包括最近针对迭代作业的专门编程模型（如 Pregel）以及这些模型未涵盖的新应用。我们在一个名为 Spark 的系统中实现了 RDDs，并通过各种用户应用程序和基准测试对其进行了评估。

## 引言

像 MapReduce 和 Dryad 这样的集群计算框架已被广泛应用于大规模数据分析。这些系统允许用户使用一组高级操作符来编写并行计算程序，而无需担心工作分配和容错问题。

尽管当前的框架为访问集群的计算资源提供了众多抽象，但它们缺乏利用分布式内存的抽象。这使得它们对于一类重要的新兴应用来说效率低下，即那些在多个计算中重复使用中间结果的应用。数据重用在许多迭代机器学习和图算法中很常见，包括 PageRank、K - 均值聚类和逻辑回归。另一个引人注目的用例是交互式数据挖掘，其中用户在数据的同一子集上运行多个临时查询。不幸的是，在大多数当前的框架中，在计算之间（例如，在两个 MapReduce 作业之间）重用数据的唯一方法是将其写入外部稳定存储系统，例如分布式文件系统。这会产生大量的开销，原因在于数据复制、磁盘 I/O 和序列化，这些开销可能会占据应用程序的执行时间。

认识到这个问题后，研究人员为一些需要数据重用的应用开发了专门的框架。例如，Pregel是一个用于迭代图计算的系统，它将中间数据保存在内存中，而 HaLoop提供了一个迭代的 MapReduce 接口。然而，这些框架仅支持特定的计算模式（例如，循环一系列 MapReduce 步骤），并且针对这些模式隐式地执行数据共享。它们没有为更一般的重用提供抽象，例如，让用户将多个数据集加载到内存中并在它们之间运行临时查询。

在本文中，我们提出了一种名为弹性分布式数据集（RDDs）的新抽象，它能够在广泛的应用中实现高效的数据重用。RDDs 是具有容错能力的并行数据结构，它允许用户显式地将中间结果持久化在内存中，控制其分区以优化数据放置，并使用丰富的操作符集对其进行操作。

在设计弹性分布式数据集（RDDs）时，主要的挑战是定义一个能够高效提供容错能力的编程接口。现有的集群内存存储抽象，如分布式共享内存、键值存储、数据库和 Piccolo，提供了一个基于可变状态（例如，表中的单元）的细粒度更新的接口。使用这个接口，提供容错的唯一方法是在机器之间复制数据或在机器之间记录更新。对于数据密集型工作负载，这两种方法都很昂贵，因为它们需要在集群网络上复制大量数据，而集群网络的带宽远低于随机存取存储器（RAM）的带宽，并且会产生大量的存储开销。

与这些系统相比，RDDs 提供了一个基于粗粒度转换（例如，映射、过滤和连接）的接口，这些转换将相同的操作应用于许多数据项。这使得它们能够通过记录用于构建数据集的转换（其血统）而不是实际数据来有效地提供容错能力。如果一个 RDD 的分区丢失，RDD 有足够的信息表明它是如何从其他 RDD 派生而来的，从而可以仅重新计算那个分区。因此，丢失的数据可以恢复，通常非常快，而不需要昂贵的复制。

虽然基于粗粒度转换的接口乍一看可能有限，但 RDD 非常适合许多并行应用程序，因为这些应用程序自然地对多个数据项应用相同的操作。实际上，我们表明 RDD 可以有效地表达许多迄今为止作为独立系统提出的集群编程模型，包括 MapReduce、DryadLINQ、SQL、Pregel 和 HaLoop，以及这些系统未涵盖的新应用，如交互式数据挖掘。我们相信，RDD 能够满足以前只能通过引入新框架才能满足的计算需求的能力，是 RDD 抽象强大的最有力证据。

我们在一个名为 Spark 的系统中实现了 RDD。Spark 正在加州大学伯克利分校和几家公司用于研究和生产应用。Spark 在 Scala 编程语言 中提供了一个类似于 DryadLINQ 的方便的语言集成编程接口。此外，Spark 可以交互式地从 Scala 解释器中查询大型数据集。
我们相信，Spark 是第一个允许通用编程语言以交互速度在集群上进行内存数据挖掘的系统。

我们通过微基准测试和对用户应用程序的测量来评估 RDD 和 Spark。我们表明，对于迭代应用程序，Spark 比 Hadoop 快高达 20 倍，将一个实际的数据分析报告的速度提高了 40 倍，并且可以交互式地用于扫描 1TB 的数据集，延迟为 5 - 7 秒。更重要的是，为了说明 RDD 的通用性，我们在 Spark 之上实现了 Pregel 和 HaLoop 编程模型，包括它们所采用的放置优化，作为相对较小的库（每个库 200 行代码）。

本文首先对 RDD 和 Spark 进行概述（第 2 部分）。然后我们讨论 RDD 的内部表示（第 4 部分）、我们的实现（第 5 部分）和实验结果（第 6 部分）。最后，我们讨论 RDD 如何捕获几个现有的集群编程模型（第 7 部分），综述相关工作（第 8 部分）并得出结论。