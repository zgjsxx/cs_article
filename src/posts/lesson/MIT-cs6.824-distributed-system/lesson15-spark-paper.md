---
category: 
  - 分布式系统
tag:
  - 分布式系统
---

- [弹性分布式数据集：内存集群计算的一种容错抽象](#弹性分布式数据集内存集群计算的一种容错抽象)
  - [摘要](#摘要)
  - [引言](#引言)
  - [2.弹性分布式数据集（RDDs）](#2弹性分布式数据集rdds)
    - [2.1 RDD 抽象](#21-rdd-抽象)
    - [2.2 Spark 编程接口](#22-spark-编程接口)
      - [2.2.1 示例：控制台日志挖掘](#221-示例控制台日志挖掘)
  - [4.表示 RDD](#4表示-rdd)

# 弹性分布式数据集：内存集群计算的一种容错抽象

## 摘要

我们提出了弹性分布式数据集（RDDs），这是一种分布式内存抽象，它允许程序员以容错的方式在大型集群上进行内存中的计算。RDDs 是由当前计算框架处理效率低下的两类应用所推动的：迭代算法和交互式数据挖掘工具。在这两种情况下，将数据保存在内存中可以将性能提高一个数量级。

为了有效地实现容错，RDDs 提供了一种受限形式的共享内存，它基于粗粒度的转换而不是对共享状态的细粒度更新。然而，我们表明 RDDs 具有足够的表现力，可以捕获广泛的计算类型，包括最近针对迭代作业的专门编程模型（如 Pregel）以及这些模型未涵盖的新应用。我们在一个名为 Spark 的系统中实现了 RDDs，并通过各种用户应用程序和基准测试对其进行了评估。

## 引言

像 MapReduce 和 Dryad 这样的集群计算框架已被广泛应用于大规模数据分析。这些系统允许用户使用一组高级操作符来编写并行计算程序，而无需担心工作分配和容错问题。

尽管当前的框架为访问集群的计算资源提供了众多抽象，但它们缺乏利用分布式内存的抽象。这使得它们对于一类重要的新兴应用来说效率低下，即那些在多个计算中重复使用中间结果的应用。数据重用在许多迭代机器学习和图算法中很常见，包括 PageRank、K - 均值聚类和逻辑回归。另一个引人注目的用例是交互式数据挖掘，其中用户在数据的同一子集上运行多个临时查询。不幸的是，在大多数当前的框架中，在计算之间（例如，在两个 MapReduce 作业之间）重用数据的唯一方法是将其写入外部稳定存储系统，例如分布式文件系统。这会产生大量的开销，原因在于数据复制、磁盘 I/O 和序列化，这些开销可能会占据应用程序的执行时间。

认识到这个问题后，研究人员为一些需要数据重用的应用开发了专门的框架。例如，Pregel是一个用于迭代图计算的系统，它将中间数据保存在内存中，而 HaLoop提供了一个迭代的 MapReduce 接口。然而，这些框架仅支持特定的计算模式（例如，循环一系列 MapReduce 步骤），并且针对这些模式隐式地执行数据共享。它们没有为更一般的重用提供抽象，例如，让用户将多个数据集加载到内存中并在它们之间运行临时查询。

在本文中，我们提出了一种名为弹性分布式数据集（RDDs）的新抽象，它能够在广泛的应用中实现高效的数据重用。RDDs 是具有容错能力的并行数据结构，它允许用户显式地将中间结果持久化在内存中，控制其分区以优化数据放置，并使用丰富的操作符集对其进行操作。

在设计弹性分布式数据集（RDDs）时，主要的挑战是定义一个能够高效提供容错能力的编程接口。现有的集群内存存储抽象，如分布式共享内存、键值存储、数据库和 Piccolo，提供了一个基于可变状态（例如，表中的单元）的细粒度更新的接口。使用这个接口，提供容错的唯一方法是在机器之间复制数据或在机器之间记录更新。对于数据密集型工作负载，这两种方法都很昂贵，因为它们需要在集群网络上复制大量数据，而集群网络的带宽远低于随机存取存储器（RAM）的带宽，并且会产生大量的存储开销。

与这些系统相比，RDDs 提供了一个基于粗粒度转换（例如，映射、过滤和连接）的接口，这些转换将相同的操作应用于许多数据项。这使得它们能够通过记录用于构建数据集的转换（其血统）而不是实际数据来有效地提供容错能力。如果一个 RDD 的分区丢失，RDD 有足够的信息表明它是如何从其他 RDD 派生而来的，从而可以仅重新计算那个分区。因此，丢失的数据可以恢复，通常非常快，而不需要昂贵的复制。

虽然基于粗粒度转换的接口乍一看可能有限，但 RDD 非常适合许多并行应用程序，因为这些应用程序自然地对多个数据项应用相同的操作。实际上，我们表明 RDD 可以有效地表达许多迄今为止作为独立系统提出的集群编程模型，包括 MapReduce、DryadLINQ、SQL、Pregel 和 HaLoop，以及这些系统未涵盖的新应用，如交互式数据挖掘。我们相信，RDD 能够满足以前只能通过引入新框架才能满足的计算需求的能力，是 RDD 抽象强大的最有力证据。

我们在一个名为 Spark 的系统中实现了 RDD。Spark 正在加州大学伯克利分校和几家公司用于研究和生产应用。Spark 在 Scala 编程语言 中提供了一个类似于 DryadLINQ 的方便的语言集成编程接口。此外，Spark 可以交互式地从 Scala 解释器中查询大型数据集。
我们相信，Spark 是第一个允许通用编程语言以交互速度在集群上进行内存数据挖掘的系统。

我们通过微基准测试和对用户应用程序的测量来评估 RDD 和 Spark。我们表明，对于迭代应用程序，Spark 比 Hadoop 快高达 20 倍，将一个实际的数据分析报告的速度提高了 40 倍，并且可以交互式地用于扫描 1TB 的数据集，延迟为 5 - 7 秒。更重要的是，为了说明 RDD 的通用性，我们在 Spark 之上实现了 Pregel 和 HaLoop 编程模型，包括它们所采用的放置优化，作为相对较小的库（每个库 200 行代码）。

本文的结构如下：
- 第 2 部分， 对RDD 和 Spark 进行概述
- 第 4 部分 讨论 RDD 的内部表示
- 第 5 部分讨论我们的实现
- 第 6 部分讨论实验结果
- 第 7 部分我们讨论 RDD 如何捕获几个现有的集群编程模型
- 第 8 部分综述相关工作并得出结论

## 2.弹性分布式数据集（RDDs）

本节对弹性分布式数据集（RDDs）进行概述。首先定义 RDDs（2.1 节）并介绍其在 Spark 中的编程接口（2.2 节）。然后将 RDDs 与更细粒度的共享内存抽象进行比较（2.3 节）。最后，讨论 RDD 模型的局限性（2.4 节）。

### 2.1 RDD 抽象

从形式上讲，弹性分布式数据集（RDD）是一个只读的、分区的记录集合。RDD 只能通过对以下两者之一进行确定性操作来创建：（1）稳定存储中的数据；（2）其他 RDD。我们将这些操作称为转换，以区别于对 RDD 的其他操作。转换的例子包括映射（map）、过滤（filter）和连接（join）。

RDD 并非在所有时候都需要被具体化。相反，一个 RDD 拥有足够的关于它是如何从其他数据集派生而来的信息（它的血统），以便从稳定存储中的数据计算出它的分区。这是一个强大的属性：本质上，一个程序不能引用一个在出现故障后无法重新构建的 RDD。

最后，用户可以控制 RDD 的另外两个方面：持久性和分区。用户可以指出他们将重用哪些 RDD，并为它们选择一种存储策略（例如，内存存储）。他们还可以要求根据每个记录中的一个键将 RDD 的元素跨机器进行分区。这对于放置优化很有用，例如确保要连接在一起的两个数据集以相同的方式进行哈希分区。

### 2.2 Spark 编程接口
Spark 通过一种与 DryadLINQ 和 FlumeJava 类似的语言集成 API 来展示 RDD，在这种 API 中，每个数据集都表示为一个对象，并且通过对这些对象调用方法来执行转换操作。

程序员首先通过对稳定存储中的数据进行转换（例如映射和过滤）来定义一个或多个 RDD。然后，他们可以在行动（actions）中使用这些 RDD，行动是指那些向应用程序返回一个值或者将数据导出到存储系统的操作。行动的例子包括计数（count，返回数据集中的元素数量）、收集（collect，返回元素本身）以及保存（save，将数据集输出到存储系统）。与 DryadLINQ 一样，Spark 在行动中首次使用 RDD 时会延迟计算它们，以便能够将转换操作进行流水线处理。

此外，程序员可以调用持久化方法（persist method）来表明他们希望在未来的操作中重用哪些 RDD。默认情况下，Spark 将持久化的 RDD 保存在内存中，但如果内存不足，它可以将其溢出到磁盘上。用户还可以通过向持久化方法传入标志来请求其他持久化策略，例如仅将 RDD 存储在磁盘上或者在多台机器上复制它。最后，用户可以为每个 RDD 设置一个持久化优先级，以指定哪些内存中的数据应该首先溢出到磁盘上。

#### 2.2.1 示例：控制台日志挖掘

假设一个网络服务出现错误，操作员想要在 Hadoop 文件系统（HDFS）中搜索数 TB 的日志以找到原因。使用 Spark，操作员可以将日志中的仅错误消息加载到一组节点的内存中，并进行交互式查询。

她首先会输入以下 Scala 代码：

```scala
lines = spark.textFile("hdfs://...")
errors = lines.filter(_.startsWith("ERROR"))
errors.persist()
```

第 1 行定义了一个由 HDFS 文件支持的 RDD（作为文本行的集合），而第 2 行从它派生一个经过过滤的 RDD。第 3 行随后要求将错误持久化到内存中，以便可以在查询之间共享。请注意，传递给过滤器的参数是闭包的 Scala 语法。

此时，在集群上还没有执行任何工作。然而，用户现在可以在行动中使用这个 RDD，例如，计算消息的数量：

```scala
errors.count()
```

用户还可以对 RDD 执行进一步的转换操作，并使用其结果，如下所示：

```scala
// Count errors mentioning MySQL:
errors.filter(_.contains("MySQL")).count()

// Return the time fields of errors mentioning
// HDFS as an array (assuming time is field
// number 3 in a tab-separated format):
errors.filter(_.contains("HDFS"))
.map(_.split('\t')(3))
.collect()
```

在涉及 "errors" 的第一个行动运行后，Spark 将把 "errors" 的分区存储在内存中，这极大地加快了后续对它的计算。请注意，基础 RDD "lines" 并没有加载到内存中。这是可取的，因为错误消息可能只是数据的一小部分（小到足以放入内存中）。

最后，为了说明我们的模型是如何实现容错性的，我们在图 1 中展示了我们第三个查询中 RDD 的血统图。在这个查询中，我们从 "errors" 开始，它是对 "lines" 进行过滤的结果，在运行 "collect" 之前应用了进一步的过滤和映射。Spark 调度器将把后两个转换操作进行流水线处理，并将一组计算它们的任务发送到持有 "errors" 缓存分区的节点上。此外，如果 "errors" 的一个分区丢失，Spark 将仅在 "lines" 的相应分区上应用过滤操作来重新构建它。


## 4.表示 RDD

在将 RDD 作为一种抽象提供时，其中一个挑战是为它们选择一种能够在各种转换中跟踪血统的表示形式。理想情况下，实现 RDD 的系统应该提供尽可能丰富的一组转换操作符（例如，表 2 中的那些），并让用户以任意方式组合它们。我们为 RDD 提出一种简单的基于图的表示形式，这种形式有助于实现这些目标。我们在 Spark 中使用了这种表示形式来支持广泛的转换，而无需为每个转换在调度器中添加特殊逻辑，这极大地简化了系统设计。

简而言之，我们建议通过一个通用接口来表示每个 RDD，该接口公开五部分信息：一组分区，它们是数据集的原子部分；一组对父 RDD 的依赖关系；一个基于其父级计算数据集的函数；以及关于其分区方案和数据放置的元数据。例如，代表一个 HDFS 文件的 RDD 对文件的每个块都有一个分区，并且知道每个块位于哪些机器上。同时，对这个 RDD 进行映射的结果具有相同的分区，但在计算其元素时将映射函数应用于父级的数据。我们在表 3 中总结了这个接口。

在设计接口时，如何表示 RDD 之间的依赖关系是一个有趣的问题。我们发现将依赖关系分为两种类型既充分又有用，即：
- 窄依赖，其中父 RDD 的每个分区最多被子 RDD 的一个分区使用；
- 宽依赖，其中多个子分区可能依赖于它。例如，映射导致窄依赖，而连接导致宽依赖（除非父级是哈希分区的）。图 4 展示了其他例子。

![图4：宽依赖和窄依赖的例子。其中每个方框都是一个 RDD，分区显示为蓝色填充的矩形。](https://github.com/zgjsxx/static-img-repo/raw/main/blog/lesson/6.824/lesson13/paper/read-write-trx.png)


